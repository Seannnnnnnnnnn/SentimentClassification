{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3eba461",
   "metadata": {},
   "source": [
    "### Twitter Sentiment Analysis\n",
    "\n",
    "There are various files in these archives: other than this README, each one can be identified by its filename, in the format {set}_{type}.{filetype}\n",
    "- {set} refers to either train, dev, or test:\n",
    "\n",
    "\n",
    "    train: You should use this data when building a model\n",
    "    dev: You should use this data when evaluating a model\n",
    "    test: You should submit the outputs on this data to Kaggle; the labels are not given\n",
    "   \n",
    "- {type} refers to either full, count, tfidf, glove100:\n",
    "    \n",
    "    \n",
    "    full: This contains the raw text of the corresponding tweets, one tweet per line, in the following format:\n",
    "          sentiment, tweet_id, tweet (newline)\n",
    "         \n",
    "where sentiment is the class label (to be predicted), the tweet_id identifies the tweet, and the Tweet-text the raw tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72bc8d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis.ipynb   dev_glove.csv    test_glove.csv   train_glove.csv\r\n",
      "README.txt       dev_tfidf.csv    test_tfidf.csv   train_tfidf.csv\r\n",
      "dev_count.csv    test_count.csv   train_count.csv  vocab.txt\r\n",
      "dev_full.csv     test_full.csv    train_full.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbdedfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from math import sqrt, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac96486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets : 159253\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>@bullyosullivan oh no! so sorry about your pet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>2</td>\n",
       "      <td>@anneaam you should! i love prison break.i onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>3</td>\n",
       "      <td>i saw some really nice pair of shoess.. couldn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>4</td>\n",
       "      <td>hihihi i had fun but my foot is still hurting!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>5</td>\n",
       "      <td>sourish limbs is preventing me from gg out on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  tweet_id                                              tweet\n",
       "0       neg         1  @bullyosullivan oh no! so sorry about your pet...\n",
       "1       neg         2  @anneaam you should! i love prison break.i onl...\n",
       "2       neg         3  i saw some really nice pair of shoess.. couldn...\n",
       "3       neg         4  hihihi i had fun but my foot is still hurting!...\n",
       "4       neg         5  sourish limbs is preventing me from gg out on ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_full = pd.read_csv(\"train_full.csv\")\n",
    "print(f\"Number of tweets : {dataframe_full.shape[0]}\")\n",
    "dataframe_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5524be07",
   "metadata": {},
   "source": [
    "### Benchmarking\n",
    "We first do some exploratory analysis and construct some basic benchmarks for model performance. As we see, the dataset is skewed towards `pos` and `neg` labels, which combine to make up $\\approx80\\%$ of the labels. Thus we can say that the dataset is slightly imbalanced, which might be problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c021547d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    0.407352\n",
       "pos    0.392124\n",
       "neu    0.200524\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe_full['sentiment'].value_counts().plot(kind='barh')\n",
    "dataframe_full['sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3af263",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "So far our *features* involve only the actual tweet itself, we now engineer some additional features. Using several resources online, we can find some inspiration for engineering features in the NLP context. As an occasional twitter user, there is also some slight domain context for what suggests a tweets polarity, such as hashtags and mentions. We implement python functions below for performing feature extraction, we then apply these features to `dataframe_full`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc7eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) # we create this as a global variable\n",
    "    \n",
    "\n",
    "def num_chars(tweet: str):\n",
    "    return len(tweet)\n",
    "\n",
    "\n",
    "def num_words(tweet: str):\n",
    "    return len(tweet.split())\n",
    "\n",
    "\n",
    "def num_cap_words(tweet: str):\n",
    "    return sum(map(str.isupper, tweet.split()))\n",
    "\n",
    "\n",
    "def num_hashtags(tweet: str): \n",
    "    return tweet.count('#')\n",
    "\n",
    "\n",
    "def num_mentions(tweet: str):\n",
    "    return tweet.count('@')\n",
    "\n",
    "\n",
    "def num_stopwords(tweet: str):  \n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    stopwords_tweet = [w for w in word_tokens if w in stop_words]\n",
    "    return len(stopwords_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07eaad88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_cap_words</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>avg_wordlength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>@bullyosullivan oh no! so sorry about your pet...</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>2</td>\n",
       "      <td>@anneaam you should! i love prison break.i onl...</td>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>3</td>\n",
       "      <td>i saw some really nice pair of shoess.. couldn...</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>4</td>\n",
       "      <td>hihihi i had fun but my foot is still hurting!...</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>5</td>\n",
       "      <td>sourish limbs is preventing me from gg out on ...</td>\n",
       "      <td>135</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4.655172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  tweet_id                                              tweet  \\\n",
       "0       neg         1  @bullyosullivan oh no! so sorry about your pet...   \n",
       "1       neg         2  @anneaam you should! i love prison break.i onl...   \n",
       "2       neg         3  i saw some really nice pair of shoess.. couldn...   \n",
       "3       neg         4  hihihi i had fun but my foot is still hurting!...   \n",
       "4       neg         5  sourish limbs is preventing me from gg out on ...   \n",
       "\n",
       "   num_chars  num_words  num_cap_words  num_hashtags  num_mentions  \\\n",
       "0         50          8              0             0             1   \n",
       "1         66         13              0             0             1   \n",
       "2         58         11              0             0             0   \n",
       "3         63         13              0             0             0   \n",
       "4        135         29              0             0             0   \n",
       "\n",
       "   num_stopwords  avg_wordlength  \n",
       "0              4        6.250000  \n",
       "1              5        5.076923  \n",
       "2              3        5.272727  \n",
       "3              7        4.846154  \n",
       "4             18        4.655172  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_features = [num_chars, num_words, num_cap_words, num_hashtags, num_mentions, \n",
    "                       num_stopwords]\n",
    "\n",
    "for feature in engineered_features:         # this is just a fancy way to loop our feature functions and apply them\n",
    "    dataframe_full[feature.__name__] = dataframe_full[\"tweet\"].apply(lambda x: feature(x))\n",
    "\n",
    "dataframe_full['avg_wordlength'] = dataframe_full['num_chars']/dataframe_full['num_words']\n",
    "dataframe_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc34ecc",
   "metadata": {},
   "source": [
    "### Preprocesssing\n",
    "Having engineered some features, our dataset is still *messy* and could be improved with some preprocessing of features before applying to a statisical learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91662357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0347ab",
   "metadata": {},
   "source": [
    "### Linear classification models : Training\n",
    "\n",
    "Having engineered several features from our dataset of tweets, we can begin to implement and train some classification models. We begin by applying linear classification models; ones that determine a linear decision boundary between class labels. If the engineered dataset is indeed linearly separable, we will see strong performance across these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1403da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first separate out our features from our labels and drop non-features such as tweet_id\n",
    "df_full = dataframe_full            \n",
    "y = df_full['sentiment']\n",
    "X = df_full.drop(['sentiment', 'tweet_id', 'tweet'], 1)\n",
    "\n",
    "assert y.shape[0] == X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbce80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "l2_logistic_regression = LogisticRegression(penalty='l2', random_state=0, max_iter=10000).fit(X, y)\n",
    "l1_logistic_regression = LogisticRegression(penalty='none',random_state=0, max_iter=10000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "802cfa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian_nb = GaussianNB().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "949b3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "L2_knn = KNeighborsClassifier(n_neighbors=floor(sqrt(X.shape[0]))).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653820e3",
   "metadata": {},
   "source": [
    "### Linear classification models : Testing\n",
    "\n",
    "Having used `train_full` to train the model, we now turn to testing and evaluating the models using the `dev_full` dataset. As this dataset intially contains only `tweet_id` and `tweet` as features, we pass it through the same pipeline of feature engineering and preprocessing as our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e1322f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_pipeline(dataframe: pd.DataFrame):\n",
    "    # applies the transformation pipeline to the testing data frame, return labels and feature matrix\n",
    "    \n",
    "    for feature in engineered_features:         \n",
    "        dataframe[feature.__name__] = dataframe[\"tweet\"].apply(lambda x: feature(x))\n",
    "    \n",
    "    dataframe['avg_wordlength'] = dataframe['num_chars']/dataframe['num_words']\n",
    "    \n",
    "    y = dataframe['sentiment']\n",
    "    X = dataframe.drop(['sentiment', 'tweet_id', 'tweet'], 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52621a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159253 test instances\n",
      "L2 Logistic Regression Accuary score : 0.5689741786396062\n",
      "L1 Logistic Regression Accuary score : 0.5694765397367628\n",
      "\n",
      "Gaussian Naive Bayes Accuary score   : 0.5369235406410128\n",
      "\n",
      "L2 kNN Accuary score   : 0.5599316788907867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_set = pd.read_csv(\"dev_full.csv\")\n",
    "X_test, y_test = transformation_pipeline(test_set)\n",
    "print(f\"{X.shape[0]} test instances\")\n",
    "\n",
    "\n",
    "# evaluation of Logistic Regression: \n",
    "l2_lr_pred = l2_logistic_regression.predict(X_test)\n",
    "l1_lr_pred = l1_logistic_regression.predict(X_test)\n",
    "print(f\"L2 Logistic Regression Accuary score : {accuracy_score(l2_lr_pred, y_test)}\")\n",
    "print(f\"L1 Logistic Regression Accuary score : {accuracy_score(l1_lr_pred, y_test)}\\n\")\n",
    "\n",
    "\n",
    "# evaluation of Naive Bayes: \n",
    "nb_pred = gaussian_nb.predict(X_test)\n",
    "print(f\"Gaussian Naive Bayes Accuary score   : {accuracy_score(nb_pred, y_test)}\\n\")\n",
    "\n",
    "\n",
    "# evaluation of kNN:\n",
    "L2_kNN_pred = L2_knn.predict(X_test)\n",
    "print(f\"L2 kNN Accuary score   : {accuracy_score(L2_kNN_pred, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
